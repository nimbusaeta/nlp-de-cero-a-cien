{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nlp-en-es/nlp-de-cero-a-cien/blob/main/1_word_embeddings/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvNCXd9Dfqe1"
   },
   "source": [
    "#Word2vec con Gensim\n",
    "\n",
    "En este cuaderno de Jupyter vas a utilizar la biblioteca [Gensim](https://radimrehurek.com/gensim/index.html) para experimentar con word2vec. Este cuaderno est谩 enfocado en la intuici贸n de los conceptos y no en los detalles de implementaci贸n. Este cuaderno est谩 inspirado en esta [gu铆a](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html).\n",
    "\n",
    "##1. Instalaci贸n y cargar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKIqnDXXfpiz"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Sn7Q2jB3frOn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leticia\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yBaT8djWkaZy"
   },
   "outputs": [],
   "source": [
    "model = api.load('word2vec-google-news-300') # tarda unos cuantos minutos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVZm7iTOoawW"
   },
   "source": [
    "## 2. Similitud de palabras\n",
    "\n",
    "En esta secci贸n veremos c贸mo conseguir la similitud entre dos palabras utilizando un word embedding ya entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kOZfaelLoi4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6510957"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"king\", \"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BX-Kk9HZofuF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22942673"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"king\", \"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ypFK-pLrol3N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09978465"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"king\", \"potato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rBWzZySFormq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"king\", \"king\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935371"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"nine\", \"eight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GijWs_tx83W"
   },
   "source": [
    "Ahora veremos c贸mo encontrar las palabras con mayor similitud al conjunto de palabras especificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ytELAWBLk2-6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('monarch', 0.7042067050933838),\n",
       " ('kings', 0.6780861616134644),\n",
       " ('princess', 0.6731551885604858),\n",
       " ('queens', 0.6679497957229614),\n",
       " ('prince', 0.6435247659683228)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar([\"king\", \"queen\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "7D4ZS7N3ovxB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('carrots', 0.7536594867706299),\n",
       " ('tomatoes', 0.7129638195037842),\n",
       " ('celery', 0.7025030851364136),\n",
       " ('broccoli', 0.6796350479125977),\n",
       " ('cherry_tomatoes', 0.662927508354187)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar([\"tomato\", \"carrot\"], topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZFlxKjOyBpu"
   },
   "source": [
    "Pero incluso puedes hacer cosas interesantes como ver qu茅 palabra no corresponde a una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "8CrZdcBpn3pn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'three'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match([\"six\", \"seven\", \"three\", \"four\", \"five\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ko09hZ3dqMZ1"
   },
   "source": [
    "##Ejercicios\n",
    "\n",
    "1. Usa el modelo word2vec para hacer un ranking de las siguientes 15 palabras seg煤n su similitud con las palabras \"man\" y \"woman\". Para cada par, imprime su similitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "vzZ1eD3PpT-d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De m谩s a menos similares a 'man':\n",
      "man se parece a 'man' un 100.0 %\n",
      "woman se parece a 'man' un 76.64 %\n",
      "husband se parece a 'man' un 34.5 %\n",
      "wife se parece a 'man' un 32.92 %\n",
      "child se parece a 'man' un 31.63 %\n",
      "doctor se parece a 'man' un 31.45 %\n",
      "nurse se parece a 'man' un 25.47 %\n",
      "teacher se parece a 'man' un 25.0 %\n",
      "king se parece a 'man' un 22.94 %\n",
      "queen se parece a 'man' un 16.66 %\n",
      "scientist se parece a 'man' un 15.82 %\n",
      "engineer se parece a 'man' un 15.13 %\n",
      "birth se parece a 'man' un 11.08 %\n",
      "professor se parece a 'man' un 9.42 %\n",
      "president se parece a 'man' un 2.84 %\n",
      "\n",
      "De m谩s a menos similares a 'woman':\n",
      "woman se parece a 'woman' un 100.0 %\n",
      "man se parece a 'woman' un 76.64 %\n",
      "husband se parece a 'woman' un 49.28 %\n",
      "child se parece a 'woman' un 47.5 %\n",
      "wife se parece a 'woman' un 44.48 %\n",
      "nurse se parece a 'woman' un 44.14 %\n",
      "doctor se parece a 'woman' un 37.95 %\n",
      "queen se parece a 'woman' un 31.62 %\n",
      "teacher se parece a 'woman' un 31.36 %\n",
      "birth se parece a 'woman' un 21.47 %\n",
      "scientist se parece a 'woman' un 15.49 %\n",
      "professor se parece a 'woman' un 13.08 %\n",
      "king se parece a 'woman' un 12.85 %\n",
      "engineer se parece a 'woman' un 9.44 %\n",
      "president se parece a 'woman' un 6.27 %\n"
     ]
    }
   ],
   "source": [
    "words = [\n",
    "\"wife\",\n",
    "\"husband\",\n",
    "\"child\",\n",
    "\"queen\",\n",
    "\"king\",\n",
    "\"man\",\n",
    "\"woman\",\n",
    "\"birth\",\n",
    "\"doctor\",\n",
    "\"nurse\",\n",
    "\"teacher\",\n",
    "\"professor\",\n",
    "\"engineer\",\n",
    "\"scientist\",\n",
    "\"president\"]\n",
    "\n",
    "dicc_man = {}\n",
    "dicc_wom = {}\n",
    "for word in words:\n",
    "    dicc_man[word] = model.similarity(\"man\", word)\n",
    "    dicc_wom[word] = model.similarity(\"woman\", word)\n",
    "\n",
    "tuples_list_man = sorted(dicc_man.items(), key = lambda kv: kv[1], reverse=True)\n",
    "tuples_list_wom = sorted(dicc_wom.items(), key = lambda kv: kv[1], reverse=True)\n",
    "\n",
    "print(\"De m谩s a menos similares a 'man':\")\n",
    "for tupla in tuples_list_man:\n",
    "    print(tupla[0], \"se parece a 'man' un\", round(tupla[1]*100, 2), \"%\")\n",
    "\n",
    "print()\n",
    "print(\"De m谩s a menos similares a 'woman':\")\n",
    "for tupla in tuples_list_wom:\n",
    "    print(tupla[0], \"se parece a 'woman' un\", round(tupla[1]*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKamywnxqxJJ"
   },
   "source": [
    "**2. Completa las siguientes analog铆as por tu cuenta (sin usar el modelo)**\n",
    "\n",
    "a. king is to throne as judge is to _bench_\n",
    "\n",
    "b. giant is to dwarf as genius is to _fool_\n",
    "\n",
    "c. French is to France as Spaniard is to _Spain_\n",
    "\n",
    "d. bad is to good as sad is to _happy_\n",
    "\n",
    "e. nurse is to hospital as teacher is to _school_\n",
    "\n",
    "f. universe is to planet as house is to _room_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcNRxHuZrXAM"
   },
   "source": [
    "**3. Ahora completa las analog铆as usando un modelo word2vec**\n",
    "\n",
    "Aqu铆 hay un ejemplo de c贸mo hacerlo. Puedes resolver analog铆as como \"A es a B como C es a _\" haciendo A + C - B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar(tupla, pred):\n",
    "    if tupla[0][0] == pred:\n",
    "        print(\"コ\")\n",
    "    else:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('appellate_court', 0.5845253467559814)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# king is to throne as judge is to bench?\n",
    "tupla = model.most_similar(positive=[\"judge\", \"throne\"], negative=[\"king\"], topn=1)\n",
    "print(tupla)\n",
    "evaluar(tupla, \"bench\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('savant', 0.44152510166168213)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# giant is to dwarf as genius is to fool?\n",
    "tupla = model.most_similar(positive=[\"genius\", \"dwarf\"], negative=[\"giant\"], topn=1)\n",
    "print(tupla)\n",
    "evaluar(tupla, \"fool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rider_Dani_Pedrosa', 0.5646752119064331)]\n",
      "\n",
      "[('Spain', 0.8138449192047119)]\n",
      "コ\n"
     ]
    }
   ],
   "source": [
    "# French is to France as Spaniard is to Spain?\n",
    "tupla = model.most_similar(positive=[\"Spaniard\", \"France\"], negative=[\"French\"], topn=1)\n",
    "print(tupla)\n",
    "evaluar(tupla, \"Spain\")\n",
    "\n",
    "tupla = model.most_similar(positive=[\"Spanish\", \"France\"], negative=[\"French\"], topn=1)\n",
    "print(tupla)\n",
    "evaluar(tupla, \"Spain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('wonderful', 0.6414927840232849)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bad is to good as sad is to happy?\n",
    "tupla = model.most_similar(positive=[\"sad\", \"good\"], negative=[\"bad\"], topn=1)\n",
    "print(tupla)\n",
    "evaluar(tupla, \"happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('school', 0.60170978307724)]\n",
      "コ\n"
     ]
    }
   ],
   "source": [
    "# nurse is to hospital as teacher is to school?\n",
    "tupla = model.most_similar(positive=[\"teacher\", \"hospital\"], negative=[\"nurse\"], topn=1)\n",
    "print(tupla)\n",
    "evaluar(tupla, \"school\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bungalow', 0.5428240299224854)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# universe is to planet as house is to room?\n",
    "tupla = model.most_similar(positive=[\"house\", \"planet\"], negative=[\"universe\"], topn=1)\n",
    "print(tupla)\n",
    "evaluar(tupla, \"room\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JUST FOR FUN\n",
    "\n",
    "def regla_de_tres(base1, base2, target1):\n",
    "    target2, prob = model.most_similar(positive=[target1, base2], negative=[base1], topn=1)[0]\n",
    "    print(base1, \"es a\", base2, \"como\", target1, \"es a\", target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spain es a paella como Italy es a risotto\n"
     ]
    }
   ],
   "source": [
    "country_base = \"Spain\"\n",
    "country_target = \"Italy\"\n",
    "food_base = \"paella\"\n",
    "regla_de_tres(country_base, food_base, country_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italy es a pasta como Spain es a paella\n"
     ]
    }
   ],
   "source": [
    "country_base = \"Italy\"\n",
    "country_target = \"Spain\"\n",
    "food_base = \"pasta\"\n",
    "regla_de_tres(country_base, food_base, country_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italy es a lasagna como Spain es a paella\n"
     ]
    }
   ],
   "source": [
    "country_base = \"Italy\"\n",
    "country_target = \"Spain\"\n",
    "food_base = \"lasagna\"\n",
    "regla_de_tres(country_base, food_base, country_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spain es a cocido como Italy es a cucina\n"
     ]
    }
   ],
   "source": [
    "country_base = \"Spain\"\n",
    "country_target = \"Italy\"\n",
    "food_base = \"cocido\"\n",
    "regla_de_tres(country_base, food_base, country_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spain es a jam贸n como Italy es a pesce\n"
     ]
    }
   ],
   "source": [
    "country_base = \"Spain\"\n",
    "country_target = \"Italy\"\n",
    "food_base = \"jam贸n\"\n",
    "regla_de_tres(country_base, food_base, country_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italy es a formaggio como Spain es a jam贸n\n"
     ]
    }
   ],
   "source": [
    "country_base = \"Italy\"\n",
    "country_target = \"Spain\"\n",
    "food_base = \"formaggio\"\n",
    "regla_de_tres(country_base, food_base, country_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italy es a prosciutto como Spain es a Serrano_ham\n"
     ]
    }
   ],
   "source": [
    "country_base = \"Italy\"\n",
    "country_target = \"Spain\"\n",
    "food_base = \"prosciutto\"\n",
    "regla_de_tres(country_base, food_base, country_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italy es a pesto como Spain es a chorizo\n"
     ]
    }
   ],
   "source": [
    "country_base = \"Italy\"\n",
    "country_target = \"Spain\"\n",
    "food_base = \"pesto\"\n",
    "regla_de_tres(country_base, food_base, country_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spain es a chorizo como Italy es a ricotta\n"
     ]
    }
   ],
   "source": [
    "country_base = \"Spain\"\n",
    "country_target = \"Italy\"\n",
    "food_base = \"chorizo\"\n",
    "regla_de_tres(country_base, food_base, country_target)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOnghp0wIfCZSJ+lSjdKnPj",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Word2vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
